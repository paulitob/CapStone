{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests) (2.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/ba/a0e6866057fc0bbd17192925c1d63a3b85cf522965de9bc02364d08e5b84/lxml-4.5.0-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8MB 7.3MB/s eta 0:00:01     |████▋                           | 829kB 7.3MB/s eta 0:00:01     |████████▏                       | 1.5MB 7.3MB/s eta 0:00:01     |████████████████████████        | 4.3MB 7.3MB/s eta 0:00:01     |███████████████████████████▋    | 5.0MB 7.3MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: / "
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge folium=0.5.0 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import lxml\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import folium\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O 'berlin_data.csv' https://raw.githubusercontent.com/zauberware/postal-codes-json-xml-csv/240d643985f3654918665721d47e2642112d81e6/data/DE/zipcodes.de.csv\n",
    "coordinates_df = pd.read_csv('berlin_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_df = coordinates_df[coordinates_df.state != 'Bayern']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Bremen']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Hessen']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Baden-Württemberg']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Hamburg']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Mecklenburg-Vorpommern']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Niedersachsen']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Nordrhein-Westfalen']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Rheinland-Pfalz']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Schleswig-Holstein']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Saarland']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Sachsen-Anhalt']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Sachsen']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Thüringen']\n",
    "coordinates_df = coordinates_df[coordinates_df.state != 'Brandenburg']\n",
    "coordinates_df.rename(columns={'zipcode': 'Postal code', 'latitude': 'Latitude', 'longitude': 'Longitude'}, inplace=True)\n",
    "coordinates_df = coordinates_df.drop(['country_code', 'state_code', 'province', 'province_code', 'community', 'community_code', 'state'], axis =1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_berlin = folium.Map(location=[52.5323, 13.3846], zoom_start=11)\n",
    "for lat, lng, label in zip(coordinates_df['Latitude'], coordinates_df['Longitude'], coordinates_df['Postal code']):\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_berlin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'JABYZYQHJAAA1VYXYMDSTJRVRAVRXP0K51YH41BV2JBY5EBO' # your Foursquare ID\n",
    "CLIENT_SECRET = 'NUHB32I5UVYXUZG2EA5YVWMNKX1YLNYVDNSE0VQPZGRVF0YU' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "LIMIT = 50\n",
    "radius = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=2000):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Postal code', \n",
    "                  'Postal code Latitude', \n",
    "                  'Postal code Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin_venues = getNearbyVenues(names=coordinates_df['Postal code'],\n",
    "                                   latitudes=coordinates_df['Latitude'],\n",
    "                                   longitudes=coordinates_df['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin_venues.to_csv(\"berlin_venues.csv\",index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin_onehot = pd.get_dummies(berlin_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\") # one hot encoding\n",
    "\n",
    "berlin_onehot['Postal code'] = berlin_venues['Postal code'] # add Postal code column back to dataframe\n",
    "\n",
    "fixed_columns = [berlin_onehot.columns[-1]] + list(berlin_onehot.columns[:-1]) # move Postal code column to the first column\n",
    "berlin_onehot = berlin_onehot[fixed_columns]\n",
    "\n",
    "berlin_grouped = berlin_onehot.groupby('Postal code').mean().reset_index() # group rows by Postal code and by taking the mean of the frequency of occurrence of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print each Postal code along with the top 5 most common venues\n",
    "num_top_venues = 50\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Postal code']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "Postal_code_venues_sorted = pd.DataFrame(columns=columns)\n",
    "Postal_code_venues_sorted['Postal code'] = berlin_grouped['Postal code']\n",
    "\n",
    "for ind in np.arange(berlin_grouped.shape[0]):\n",
    "    Postal_code_venues_sorted.iloc[ind, 1:] = return_most_common_venues(berlin_grouped.iloc[ind, :], num_top_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using an elbow plot to see at what value of k, the distance between the mean of a cluster and the other data points in the cluster is at its lowest.\n",
    "sum_of_squared_distances = []\n",
    "K = range(1,30)\n",
    "berlin_grouped_clustering = berlin_grouped.drop('Postal code', 1)\n",
    "for k in K:\n",
    "    k_means = KMeans(n_clusters=k)\n",
    "    model = k_means.fit(berlin_grouped_clustering)\n",
    "    sum_of_squared_distances.append(k_means.inertia_)\n",
    "    \n",
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('sum_of_squared_distances')\n",
    "plt.title('elbow method for optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the Postal codes\n",
    "\n",
    "# set number of clusters\n",
    "kclusters = 23\n",
    "\n",
    "berlin_grouped_clustering = berlin_grouped.drop('Postal code', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(berlin_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Postal_code_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create a new dataframe that includes the cluster as well as the top 10 venues for each Postal code\n",
    "\n",
    "# add clustering labels\n",
    "Postal_code_venues_sorted.insert(0, 'ClusterLabels', kmeans.labels_)\n",
    "\n",
    "berlin_merged = coordinates_df\n",
    "\n",
    "# merge berlin_grouped with berlin_data to add latitude/longitude for each Postal code\n",
    "berlin_merged = berlin_merged.join(Postal_code_venues_sorted.set_index('Postal code'), on='Postal code')\n",
    "berlin_merged = berlin_merged.dropna()\n",
    "berlin_merged = berlin_merged.astype({'ClusterLabels': int})\n",
    "\n",
    "berlin_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[52.5323, 13.3846], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(berlin_merged['Latitude'], berlin_merged['Longitude'], berlin_merged['Postal code'], berlin_merged['ClusterLabels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin_merged.to_csv(\"output_filename.csv\", index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
